{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Transverse Chromatic Aberration Correction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-1-631db1acc53c&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquote\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---&gt; 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtca_correction\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-&gt;\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "# \n",
    "#   Rio\n",
    "#   Copyright (c) 2020 Homedeck, LLC.\n",
    "#\n",
    "\n",
    "from json import dumps\n",
    "from PIL import Image\n",
    "from requests import get, put\n",
    "from torch import cat, enable_grad, linspace, meshgrid, stack, tensor, Tensor\n",
    "from torch.nn import L1Loss, Parameter\n",
    "from torch.nn.functional import grid_sample\n",
    "from torch.optim import SGD\n",
    "from torchvision.transforms import ToPILImage, ToTensor\n",
    "from typing import List\n",
    "from urllib.parse import quote\n",
    "\n",
    "from .device import get_device\n",
    "\n",
    "def tca_correction (*images: Image.Image) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Appply transverse chromatic aberration correction on an image.\n",
    "\n",
    "    Parameters:\n",
    "        images (PIL.Image | list): Input image(s).\n",
    "        coefficients (Tensor): Cubic red-blue TCA coefficients with shape (2,4). If `None`, it will be computed (can be slow).\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image | list: Corrected image(s).\n",
    "    \"\"\"\n",
    "    # Check images\n",
    "    if len(images) == 0:\n",
    "        return []\n",
    "    # Fetch coefficients\n",
    "    coefficients = _fetch_coefficients(images)\n",
    "    if coefficients is None:\n",
    "        return images if len(images) > 1 else images[0]\n",
    "    # Save EXIF\n",
    "    exifs = [image.info.get(\"exif\") for image in images]\n",
    "    # Create exposure stack tensor\n",
    "    device = get_device()\n",
    "    image_tensors = [ToTensor()(image) for image in images]\n",
    "    exposure_stack = stack(image_tensors, dim=0).to(device)\n",
    "    coefficients = coefficients.to(device)\n",
    "    # Apply\n",
    "    result_stack = _tca_forward(exposure_stack, coefficients)\n",
    "    # Convert back to image\n",
    "    exposures = result_stack.split(1, dim=0)\n",
    "    images = [ToPILImage()(exposure.squeeze(dim=0).cpu()) for exposure in exposures]\n",
    "    # Add EXIF and return\n",
    "    for image, exif in zip(images, exifs):\n",
    "        image.info[\"exif\"] = exif\n",
    "    return images if len(images) > 1 else images[0]\n",
    "\n",
    "def _fetch_coefficients (images: List[Image.Image]) -> Tensor:\n",
    "    \"\"\"\n",
    "    Fetch coefficients for TCA correction.\n",
    "    If coefficients are not available, they will be computed.\n",
    "\n",
    "    Parameters:\n",
    "        images (list): Input images.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Quadratic red-blue TCA coefficients with shape (2,3).\n",
    "    \"\"\"\n",
    "    # Get EXIF metadata\n",
    "    CAMERA_MAKER_EXIF_TAG = 271\n",
    "    LENS_MAKER_EXIF_TAG = 42035\n",
    "    LENS_MODEL_EXIF_TAG = 42036\n",
    "    FOCAL_LENGTH_EXIF_TAG = 37386\n",
    "    metadata = images[0].getexif()\n",
    "    if metadata is None:\n",
    "        print(\"Rio Error: Image does not have EXIF metadata for TCA correction\")\n",
    "        return None\n",
    "    camera_maker = metadata.get(CAMERA_MAKER_EXIF_TAG)\n",
    "    lens_maker = metadata.get(LENS_MAKER_EXIF_TAG) or camera_maker\n",
    "    lens_model = metadata.get(LENS_MODEL_EXIF_TAG)\n",
    "    focal_length = metadata.get(FOCAL_LENGTH_EXIF_TAG)\n",
    "    if lens_maker is None or lens_model is None or focal_length is None:\n",
    "        print(\"Rio Error: Image does not have lens metadata for TCA correction\")\n",
    "        return None\n",
    "    # Fetch coefficients\n",
    "    lens_maker = quote(lens_maker.replace(\".\", \"_\").replace(\"/\", \"_\"))\n",
    "    lens_model = quote(lens_model.replace(\".\", \"_\").replace(\"/\", \"_\"))\n",
    "    focal_length = focal_length[0] / focal_length[1] if isinstance(focal_length, tuple) else focal_length\n",
    "    focal_length = f\"{float(focal_length):.3f}\".replace(\".\", \"_\")\n",
    "    uri = f\"https://homedeck-rio.firebaseio.com/tca/{lens_maker}/{lens_model}/{focal_length}.json\"\n",
    "    response = get(uri)\n",
    "    coefficients = response.json()\n",
    "    KEYS = [\"ra\", \"rb\", \"rc\", \"ba\", \"bb\", \"bc\"]\n",
    "    if response.status_code == 200 and coefficients is not None:\n",
    "        ra, rb, rc, ba, bb, bc = [float(coefficients[key]) for key in KEYS]\n",
    "        coefficients = tensor([\n",
    "            [ra, rb, rc],\n",
    "            [ba, bb, bc]\n",
    "        ])\n",
    "        return coefficients\n",
    "    # Compute coefficients\n",
    "    coefficients = _compute_coefficients(images)\n",
    "    if coefficients is None:\n",
    "        return None\n",
    "    # Upload coefficients\n",
    "    payload = { k: v for k, v in zip(KEYS, coefficients.flatten().tolist()) }\n",
    "    response = put(uri, data=dumps(payload))\n",
    "    # Return\n",
    "    return coefficients\n",
    "\n",
    "def _compute_coefficients (images: List[Image.Image]) -> Tensor: # INCOMPLETE\n",
    "    \"\"\"\n",
    "    Compute cubic transverse chromatic aberration correction coefficients.\n",
    "    Once computed, these coefficients can be applied to all images captured by the same camera and lens pair.\n",
    "    If the coefficients cannot be computed, `None` is returned.\n",
    "\n",
    "    Parameters:\n",
    "        images (list): Input images.\n",
    "    \n",
    "    Returns:\n",
    "        Tensor: Quadratic red-blue TCA coefficients with shape (2,3).\n",
    "    \"\"\"\n",
    "    # Get objective\n",
    "    objective = _tca_objective(images)\n",
    "    if objective is None:\n",
    "        return None\n",
    "    device = get_device()\n",
    "    objective = objective.to(device)\n",
    "    # Define coeffs # Use quadratic distortion model as in lensfun\n",
    "    coeffs = Parameter(tensor([\n",
    "        [0., 0., 1.], # red\n",
    "        [0., 0., 1.]  # blue\n",
    "    ], device=device, requires_grad=True))\n",
    "    l1_loss = L1Loss().to(device)\n",
    "    optimizer = SGD([coeffs], lr=5e-5)\n",
    "    # Optimize\n",
    "    best_coeffs = None\n",
    "    best_loss = None\n",
    "    with enable_grad(): # In case caller has disabled grad\n",
    "        for _ in range(10):\n",
    "            optimizer.zero_grad()\n",
    "            prediction = _tca_forward(objective, coeffs)\n",
    "            r, g, b = prediction.split(1, dim=1)\n",
    "            loss = l1_loss(r, g) + l1_loss(b, g)\n",
    "            if best_loss is None or loss < best_loss:\n",
    "                best_coeffs = coeffs.detach().clone()\n",
    "                best_loss = loss.detach().clone()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    # Return coefficients\n",
    "    return best_coeffs.data.cpu()\n",
    "\n",
    "def _tca_forward (input: Tensor, coefficients: Tensor):\n",
    "    \"\"\"\n",
    "    Compute the quadratic radial lens distortion forward pass.\n",
    "\n",
    "    Parameters:\n",
    "        input (Tensor): Image tensor with shape (N,3,H,W).\n",
    "        coefficients (Tensor): Quadratic red-blue TCA coefficients with shape (2,3).\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Transformed image tensor with shape (N,3,H,W).\n",
    "    \"\"\"\n",
    "    # Construct radial sampling field\n",
    "    batch, _, height, width = input.shape\n",
    "    hg, wg = meshgrid(linspace(-1., 1., height), linspace(-1., 1., width))\n",
    "    hg = hg.repeat(batch, 1, 1).unsqueeze(dim=3).to(input.device)\n",
    "    wg = wg.repeat(batch, 1, 1).unsqueeze(dim=3).to(input.device)\n",
    "    sample_field = cat([wg, hg], dim=3)\n",
    "    r_dst = sample_field.norm(dim=3, keepdim=True)\n",
    "    # Compute distortions\n",
    "    red_distortion = coefficients[0,0] * r_dst.pow(2) + coefficients[0,1] * r_dst.pow(1) + coefficients[0,2]\n",
    "    blue_distortion = coefficients[1,0] * r_dst.pow(2) + coefficients[1,1] * r_dst.pow(1) + coefficients[1,2]\n",
    "    # Compute sample grids\n",
    "    red_grid = sample_field * red_distortion\n",
    "    blue_grid = sample_field * blue_distortion\n",
    "    # Sample\n",
    "    red, green, blue = input.split(1, dim=1)\n",
    "    red_shifted = grid_sample(red, red_grid, mode=\"bilinear\", padding_mode=\"border\", align_corners=False)\n",
    "    blue_shifted = grid_sample(blue, blue_grid, mode=\"bilinear\", padding_mode=\"border\", align_corners=False)\n",
    "    # Combine\n",
    "    result = cat([red_shifted, green, blue_shifted], dim=1)\n",
    "    return result\n",
    "\n",
    "def _tca_objective (images: List[Image.Image]) -> Tensor:\n",
    "    \"\"\"\n",
    "    Select an ideal objective image for the TCA optimization.\n",
    "    This function requires the exposure bias value on all exposures.\n",
    "\n",
    "    Parameters:\n",
    "        images (list): Input images.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Objective image.\n",
    "    \"\"\"\n",
    "    # Trivial case\n",
    "    if len(images) == 1:\n",
    "        image = images[0]\n",
    "        return ToTensor()(image).unsqueeze(dim=0)\n",
    "    # Get EXIF\n",
    "    EXPOSURE_BIAS_EXIF_TAG = 37380\n",
    "    bias_values = [image.getexif().get(EXPOSURE_BIAS_EXIF_TAG) for image in images]\n",
    "    # Check\n",
    "    if any([x is None for x in bias_values]):\n",
    "        print(\"Rio Error: Images lack exposure bias for TCA objective selection\")\n",
    "        return None\n",
    "    # Get values\n",
    "    bias_values = [x[0] / x[1] if isinstance(x, tuple) else x for x in bias_values]\n",
    "    abs_bias_values = [abs(float(x)) for x in bias_values]\n",
    "    # Get lowest absolute\n",
    "    middle_exposure, _ = next(iter(sorted(zip(images, abs_bias_values), key=lambda x: x[1])))\n",
    "    return ToTensor()(middle_exposure).unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}